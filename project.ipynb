{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from pandas.io.parsers import read_csv"
      ],
      "metadata": {
        "id": "9rtfIlvKH0SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome to our CNN project!**\n",
        "\n",
        "You will design, implement, train and analyze a CNN for an image classification task (classifying traffic signs from the GTSRB dataset). You will explore how variations in the architecture affect the model's memory footprint and computational requirements."
      ],
      "metadata": {
        "id": "JxrLzqyvHF7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">First of all, define `device` variable to store the device available (cuda:0 or cpu). If you have just cpu available, you might want to use some of Colab computational power by changing the runtime type (Runtime -> Change runtime type -> T4 GPU -> Save)."
      ],
      "metadata": {
        "id": "5l5E1OQJHyYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6mXIoR-G9Jv"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step would be to download the dataset. For this exercise, we decided to use GTSRB dataset.\n",
        "\n",
        "The GTSRB dataset, short for the German Traffic Sign Recognition Benchmark, is a widely used dataset in the field of computer vision, especially for tasks involving the recognition and classification of traffic signs.\n",
        "\n",
        "Key features of the GTSRB dataset include:\n",
        "\n",
        "**High Variety:** It contains images of 43 different classes of traffic signs, such as speed limits, prohibitory signs, danger signs, and more, making it diverse and challenging for classification tasks. Names of the classes are provided in signnames.csv file.\n",
        "\n",
        "**Large Volume:** The dataset includes more than 50,000 images, divided into training and test sets. The large volume of data is suitable for training and evaluating machine learning models.\n",
        "\n",
        "**Variable Conditions:** Images in the dataset were taken under varying conditions, including different lighting, angles, distances, and weather conditions. This variability helps in training robust models that can perform well in real-world conditions.\n",
        "\n",
        "**Annotations:** Each image is annotated with the class label of the traffic sign it contains.\n",
        "\n",
        "**Image Quality:** The images are provided in different resolutions and have different sizes."
      ],
      "metadata": {
        "id": "tqJ_L5ohI866"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <figure style=\"display: inline-block; width: 49%;\">\n",
        "    <img src=\"https://production-media.paperswithcode.com/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg\" width=\"500\"/>\n",
        "  </figure>\n",
        "</div>"
      ],
      "metadata": {
        "id": "u1kd6KDQKS9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Load GTSRB dataset using `torchvision.datasets`. Download train (`train_data`) and test (`test_data`) datasets. Use `torchvision.transforms` to convert images to tensors, normalize and resize them."
      ],
      "metadata": {
        "id": "Jgs-626aK4MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "_HkErDwzI9Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you know, to properly train and test a good neural network you need 3 datasets:\n",
        "1. training data - to train the model.\n",
        "2. validation data - to assess the generalization capabilities of the model after each epoch.\n",
        "3. test data - to test a trained neural network at the end.\n",
        "\n",
        "All three datasets should have different data samples so the model does not see validation/test data while training."
      ],
      "metadata": {
        "id": "25QPihnxLnc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Split your train dataset on train and validation datasets with the train/validation ratio 8:2. Create dataloaders for train, validation and test data."
      ],
      "metadata": {
        "id": "veedJLKZM0Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "num_workers = 2\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "NHJ0S2jqLmhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is time to visualize your data. Here is an example of how we can see some random samples from the train dataset.\n",
        "> Fill in the missing line according to your normalization above."
      ],
      "metadata": {
        "id": "KN22EdgsNgin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "classes =    # load classes names from csv file\n",
        "\n",
        "\n",
        "# function to show images\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "  # get some random training images\n",
        "  sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "  img, label = train_data[sample_idx]\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  img =   # unnormalize\n",
        "\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  # print labels\n",
        "  plt.title(classes[label], fontsize=6)\n",
        "  plt.axis(\"off\")\n",
        "  # show images\n",
        "  plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YfHK83osN8nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Visualize some samples from validation and test datasets."
      ],
      "metadata": {
        "id": "XHdQYrg7OhQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "BPGzypA3Orxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point you are ready to create your own CNN Model.\n",
        "\n",
        "> Design a Basic CNN Model by implementing `__init__()` and `forward()` functions of a gived class: Start with a simple CNN model architecture:\n",
        "   - Convolutional layer 1: Use a small number of filters (e.g., 3) with a moderate kernel size (e.g., 3x3).\n",
        "   - Activation function (e.g., ReLU).\n",
        "   - Pooling layer (e.g., 2x2 max pooling).\n",
        "   - Fully connected layer to classify the signs into 43 categories (0-42)."
      ],
      "metadata": {
        "id": "SiXnPxPnOvm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class my_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "net = my_CNN()\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "ABK_WmGFQFqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Define loss and optimizer. You can start by using CrossEntropyLoss and SGD."
      ],
      "metadata": {
        "id": "Lln5GQjcQEtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "DV9luUidQm-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Design a train loop and train your network. Plot train and validation mean loss after each epoch. Save your plots. Start by training for 10 epochs then take a look at training curves. You can keep training if you think it is necessary. Print mean train values for each 2000 mini-batches. Validate on validation dataset after each epoch. Save your model after training.\n",
        "\n",
        "**You have to save your model on your local device, otherwise all saved files will be lost when the runtime is suspended or changed!**"
      ],
      "metadata": {
        "id": "zv03cL-VQqqa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-w-zXR23Mve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "xB_QzK3CQpqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To estimate the performance of the network calculate accuracy of the network based on 10000 test images."
      ],
      "metadata": {
        "id": "FUvhCvvfR6V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "ZsOwfLYRTYwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Calculate the accuracy for each class"
      ],
      "metadata": {
        "id": "WvZSy4YZTb3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "Mx2vhZYKTmOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Plot a confusion matrix for 1000 random test data samples."
      ],
      "metadata": {
        "id": "QTvdsy54TuYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "g_zwFWx7T2uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Calculate Memory Requirements**:\n",
        "   - Calculate the number of parameters in each layer (weights and biases).\n",
        "   - Estimate the memory footprint considering different data types for the parameters (e.g., 32-bit floating point).\n",
        "\n",
        "  \n",
        "*(You can write some code to help you with calculations)*"
      ],
      "metadata": {
        "id": "eCuUeUHfT6Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR ANSWER HERE\n"
      ],
      "metadata": {
        "id": "YnVtpptHT4kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Compute Computational Complexity**:\n",
        "   - Count the number of mathematical operations (multiplications and additions) in the convolutional and fully connected layers for a single forward pass."
      ],
      "metadata": {
        "id": "H87BGJAVUVp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You have completed the first part of the project!"
      ],
      "metadata": {
        "id": "hvjyCBkgUeGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <figure style=\"display: inline-block; width: 49%;\">\n",
        "    <img src=\"https://gifdb.com/images/high/congratulation-happy-minions-cheering-8b9vyjyos6rwss4q.webp\" width=\"500\"/>\n",
        "  </figure>\n",
        "</div>"
      ],
      "metadata": {
        "id": "NxOVdSi_Uxoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But you are unsatisfied by the performance of your model. You want to raise the accuracy to more than 95%."
      ],
      "metadata": {
        "id": "qZo_JlXxVMX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Modify your architecture. Use more convolutional layers, play with kernels and dimensionalities. Use any tricks of the trade you have become familiar with in this course. Feel free to change different parameters.\n",
        "\n",
        "**For each architectural modification, repeat the calculations for memory requirements and computational complexity. Save your models and document observed results.**"
      ],
      "metadata": {
        "id": "laPRolKuVeSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Present your results. Discuss the trade-offs between model complexity, memory usage, computational demand, and performance."
      ],
      "metadata": {
        "id": "KAG2MvpYWX5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHV1y5N6VKU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}